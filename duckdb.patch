diff --git a/CMakeLists.txt b/CMakeLists.txt
index aebc060c3b..12611048b0 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -83,6 +83,13 @@ if (EXTENSION_STATIC_BUILD AND "${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
 endif()
 
 option(DISABLE_UNITY "Disable unity builds." FALSE)
+option(USE_WASM_THREADS "Should threads be used" FALSE)
+if (${USE_WASM_THREADS})
+   set(WASM_THREAD_FLAGS
+       -pthread
+       -sSHARED_MEMORY=1
+   )
+endif()
 
 option(FORCE_COLORED_OUTPUT
        "Always produce ANSI-colored output (GNU/Clang only)." FALSE)
@@ -805,7 +812,6 @@ function(build_loadable_extension_directory NAME OUTPUT_DIRECTORY PARAMETERS)
             ${TARGET_NAME} PROPERTIES RUNTIME_OUTPUT_DIRECTORY_RELEASE
             "${CMAKE_BINARY_DIR}/${OUTPUT_DIRECTORY}")
   endif()
-
   if(EMSCRIPTEN)
     # Copy file.duckdb_extension.wasm to file.duckdb_extension.wasm.lib
     add_custom_command(
@@ -817,7 +823,7 @@ function(build_loadable_extension_directory NAME OUTPUT_DIRECTORY PARAMETERS)
     add_custom_command(
       TARGET ${TARGET_NAME}
       POST_BUILD
-      COMMAND emcc $<TARGET_FILE:${TARGET_NAME}>.lib -o $<TARGET_FILE:${TARGET_NAME}> -sSIDE_MODULE=1 -O3
+      COMMAND emcc $<TARGET_FILE:${TARGET_NAME}>.lib -o $<TARGET_FILE:${TARGET_NAME}> -O3 -sSIDE_MODULE=2 -sEXPORTED_FUNCTIONS="_${NAME}_init,_${NAME}_version" ${WASM_THREAD_FLAGS}
       )
   endif()
 endfunction()
diff --git a/extension/httpfs/s3fs.cpp b/extension/httpfs/s3fs.cpp
index aac3169c59..fbe59fc13c 100644
--- a/extension/httpfs/s3fs.cpp
+++ b/extension/httpfs/s3fs.cpp
@@ -203,7 +203,7 @@ unique_ptr<S3AuthParams> S3AuthParams::ReadFromStoredCredentials(FileOpener *ope
 
 	// Return the stored credentials
 	const auto &secret = secret_match.GetSecret();
-	const auto &kv_secret = dynamic_cast<const KeyValueSecret &>(secret);
+	const auto &kv_secret = checked_dynamic_cast<const KeyValueSecret &>(secret);
 
 	return make_uniq<S3AuthParams>(S3SecretHelper::GetParams(kv_secret));
 }
diff --git a/src/include/duckdb/common/exception.hpp b/src/include/duckdb/common/exception.hpp
index 2e45cb92af..46967277a7 100644
--- a/src/include/duckdb/common/exception.hpp
+++ b/src/include/duckdb/common/exception.hpp
@@ -16,6 +16,7 @@
 
 #include <vector>
 #include <stdexcept>
+#include <iostream>
 
 namespace duckdb {
 enum class PhysicalType : uint8_t;
@@ -363,4 +364,13 @@ public:
 	DUCKDB_API explicit ParameterNotResolvedException();
 };
 
+	template <typename A, typename B>
+	A&& checked_dynamic_cast (B&& target) {
+		if (dynamic_cast<typename std::remove_reference<A>::type*>(&target)) {
+			return dynamic_cast<A&>(target);
+		}
+		std::cout <<"\n"<< "checked_dynamic_cast between " << typeid(A).name() << "\tand " << typeid(B).name() << " ERRORRED\n";
+		throw FatalException("Failed checked_dynamic_cast");
+	}
+
 } // namespace duckdb
diff --git a/src/main/extension/extension_load.cpp b/src/main/extension/extension_load.cpp
index a001f2b997..c532db1b2d 100644
--- a/src/main/extension/extension_load.cpp
+++ b/src/main/extension/extension_load.cpp
@@ -110,6 +110,7 @@ bool ExtensionHelper::TryInitialLoad(DBConfig &config, FileSystem &fs, const str
 	} else {
 		filename = fs.ExpandPath(filename);
 	}
+#ifndef WASM_LOADABLE_EXTENSIONS
 	if (!fs.FileExists(filename)) {
 		string message;
 		bool exact_match = ExtensionHelper::CreateSuggestions(extension, message);
@@ -119,6 +120,181 @@ bool ExtensionHelper::TryInitialLoad(DBConfig &config, FileSystem &fs, const str
 		error = StringUtil::Format("Extension \"%s\" not found.\n%s", filename, message);
 		return false;
 	}
+#endif
+#ifdef WASM_LOADABLE_EXTENSIONS
+	auto basename = fs.ExtractBaseName(filename);
+	char *exe = NULL;
+	exe = (char *)EM_ASM_PTR(
+	    {
+		    // Next few lines should argubly in separate JavaScript-land function call
+		    // TODO: move them out / have them configurable
+
+var url =(UTF8ToString($0));
+
+    if (typeof XMLHttpRequest === "undefined" ) {
+        const os = require('os');
+        const path = require('path');
+        const fs = require('fs');
+
+        var array = url.split("/");
+        var l = array.length;
+
+        var folder = path.join(os.homedir(), ".duckdb/extensions/" + array[l - 4] + "/" + array[l - 3] + "/" + array[l - 2] + "/");
+        var filePath = path.join(folder, array[l - 1]);
+
+        try {
+            if (!fs.existsSync(folder)) {
+                fs.mkdirSync(folder, {
+                    recursive: true
+                });
+            }
+
+            if (!fs.existsSync(filePath)) {
+                const int32 = new Int32Array(new SharedArrayBuffer(8));
+var Worker = require('node:worker_threads').Worker;
+                var worker = new Worker("const {Worker,isMainThread,parentPort,workerData,} = require('node:worker_threads');var times = 0;var SAB = 23;var Z = 0;async function ZZZ(e) {var x = await fetch(e);var res = await x.arrayBuffer();Atomics.store(SAB, 1, res.byteLength);Atomics.store(SAB, 0, 1);Atomics.notify(SAB, 1);Atomics.notify(SAB, 0);Z = res;};parentPort.on('message', function(event) {if (times == 0) {times++;SAB = event;} else if (times == 1) {times++;ZZZ(event);} else {const a = new Uint8Array(Z);const b = new Uint8Array(event.buffer);var K = Z.byteLength;for (var i = 0; i < K; i++) {b[i] = a[i];}Atomics.notify(event, 0);Atomics.store(SAB, 0, 2);Atomics.notify(SAB, 0);}});", {
+                    eval: true
+                });
+                var uInt8Array;
+
+                int32[0] = 0;
+                int32[2] = 4;
+                worker.postMessage(int32);
+
+                worker.postMessage(url);
+                Atomics.wait(int32, 0, 0);
+
+                const int32_2 = new Int32Array(new SharedArrayBuffer(int32[1] + 3 - ((int32[1] + 3) % 4)));
+                worker.postMessage(int32_2);
+
+                Atomics.wait(int32, 0, 1);
+
+                var x = new Uint8Array(int32_2.buffer, 0, int32[1]);
+                uInt8Array = x;
+                worker.terminate();
+                fs.writeFileSync(filePath, uInt8Array);
+
+            } else {
+                uInt8Array = fs.readFileSync(filePath);
+            }
+        } catch (e) {
+            console.log("Error fetching module", e);
+            return 0;
+        }
+    } else {
+        const xhr = new XMLHttpRequest();
+        xhr.open("GET", url, false);
+        xhr.responseType = "arraybuffer";
+        xhr.send(null);
+        if (xhr.status != 200)
+            return 0;
+        uInt8Array = xhr.response;
+    }
+
+		    var valid = WebAssembly.validate(uInt8Array);
+		    var len = uInt8Array.byteLength;
+		    var fileOnWasmHeap = _malloc(len + 4);
+
+		var properArray = new Uint8Array(uInt8Array);
+
+		    for (var iii = 0; iii < len; iii++) {
+			    Module.HEAPU8[iii + fileOnWasmHeap + 4] = properArray[iii];
+		    }
+		    var LEN123 = new Uint8Array(4);
+		    LEN123[0] = len % 256;
+		    len -= LEN123[0];
+		    len /= 256;
+		    LEN123[1] = len % 256;
+		    len -= LEN123[1];
+		    len /= 256;
+		    LEN123[2] = len % 256;
+		    len -= LEN123[2];
+		    len /= 256;
+		    LEN123[3] = len % 256;
+		    len -= LEN123[3];
+		    len /= 256;
+		    Module.HEAPU8.set(LEN123, fileOnWasmHeap);
+                //FIXME: found how to expose those to the logger interface
+		//console.log(LEN123);
+		//console.log(properArray);
+		//console.log(new Uint8Array(Module.HEAPU8, fileOnWasmHeap, len+4));
+		// console.log('Loading extension ', UTF8ToString($1));
+
+		    // Here we add the uInt8Array to Emscripten's filesystem, for it to be found by dlopen
+		    FS.writeFile(UTF8ToString($1), new Uint8Array(uInt8Array));
+		    return fileOnWasmHeap;
+	    },
+	    filename.c_str(), basename.c_str());
+	if (!exe) {
+		throw IOException("Extension %s is not available", filename);
+	}
+
+	auto dopen_from = basename;
+	if (!config.options.allow_unsigned_extensions) {
+		// signature is the last 256 bytes of the file
+
+		string signature;
+		signature.resize(256);
+
+		D_ASSERT(exe);
+		uint64_t LEN = 0;
+		LEN *= 256;
+		LEN += ((uint8_t *)exe)[3];
+		LEN *= 256;
+		LEN += ((uint8_t *)exe)[2];
+		LEN *= 256;
+		LEN += ((uint8_t *)exe)[1];
+		LEN *= 256;
+		LEN += ((uint8_t *)exe)[0];
+		auto signature_offset = LEN - signature.size();
+
+		const idx_t maxLenChunks = 1024ULL * 1024ULL;
+		const idx_t numChunks = (signature_offset + maxLenChunks - 1) / maxLenChunks;
+		std::vector<std::string> hash_chunks(numChunks);
+		std::vector<idx_t> splits(numChunks + 1);
+
+		for (idx_t i = 0; i < numChunks; i++) {
+			splits[i] = maxLenChunks * i;
+		}
+		splits.back() = signature_offset;
+
+		for (idx_t i = 0; i < numChunks; i++) {
+			string x;
+			x.resize(splits[i + 1] - splits[i]);
+			for (idx_t j = 0; j < x.size(); j++) {
+				x[j] = ((uint8_t *)exe)[j + 4 + splits[i]];
+			}
+			ComputeSHA256String(x, &hash_chunks[i]);
+		}
+
+		string hash_concatenation;
+		hash_concatenation.reserve(32 * numChunks); // 256 bits -> 32 bytes per chunk
+
+		for (auto &hash_chunk : hash_chunks) {
+			hash_concatenation += hash_chunk;
+		}
+
+		string two_level_hash;
+		ComputeSHA256String(hash_concatenation, &two_level_hash);
+
+		for (idx_t j = 0; j < signature.size(); j++) {
+			signature[j] = ((uint8_t *)exe)[4 + signature_offset + j];
+		}
+		bool any_valid = false;
+		for (auto &key : ExtensionHelper::GetPublicKeys()) {
+			if (duckdb_mbedtls::MbedTlsWrapper::IsValidSha256Signature(key, signature, two_level_hash)) {
+				any_valid = true;
+				break;
+			}
+		}
+		if (!any_valid) {
+			throw IOException(config.error_manager->FormatException(ErrorType::UNSIGNED_EXTENSION, filename));
+		}
+	}
+	if (exe) {
+		free(exe);
+	}
+#else
 	if (!config.options.allow_unsigned_extensions) {
 		auto handle = fs.OpenFile(filename, FileFlags::FILE_FLAGS_READ);
 
@@ -179,26 +355,9 @@ bool ExtensionHelper::TryInitialLoad(DBConfig &config, FileSystem &fs, const str
 			throw IOException(config.error_manager->FormatException(ErrorType::UNSIGNED_EXTENSION, filename));
 		}
 	}
+#endif
 	auto filebase = fs.ExtractBaseName(filename);
-
 #ifdef WASM_LOADABLE_EXTENSIONS
-	EM_ASM(
-	    {
-		    // Next few lines should argubly in separate JavaScript-land function call
-		    // TODO: move them out / have them configurable
-		    const xhr = new XMLHttpRequest();
-		    xhr.open("GET", UTF8ToString($0), false);
-		    xhr.responseType = "arraybuffer";
-		    xhr.send(null);
-		    var uInt8Array = xhr.response;
-		    WebAssembly.validate(uInt8Array);
-		    console.log('Loading extension ', UTF8ToString($1));
-
-		    // Here we add the uInt8Array to Emscripten's filesystem, for it to be found by dlopen
-		    FS.writeFile(UTF8ToString($1), new Uint8Array(uInt8Array));
-	    },
-	    filename.c_str(), filebase.c_str());
-	auto dopen_from = filebase;
 #else
 	auto dopen_from = filename;
 #endif
diff --git a/src/planner/operator/logical_delete.cpp b/src/planner/operator/logical_delete.cpp
index a028a1ea6f..d9322a4ac7 100644
--- a/src/planner/operator/logical_delete.cpp
+++ b/src/planner/operator/logical_delete.cpp
@@ -14,7 +14,7 @@ LogicalDelete::LogicalDelete(TableCatalogEntry &table, idx_t table_index)
 LogicalDelete::LogicalDelete(ClientContext &context, const unique_ptr<CreateInfo> &table_info)
     : LogicalOperator(LogicalOperatorType::LOGICAL_DELETE),
       table(Catalog::GetEntry<TableCatalogEntry>(context, table_info->catalog, table_info->schema,
-                                                 dynamic_cast<CreateTableInfo &>(*table_info).table)) {
+                                                 checked_dynamic_cast<CreateTableInfo &>(*table_info).table)) {
 }
 
 idx_t LogicalDelete::EstimateCardinality(ClientContext &context) {
diff --git a/src/planner/operator/logical_insert.cpp b/src/planner/operator/logical_insert.cpp
index 3846ed0097..830126809e 100644
--- a/src/planner/operator/logical_insert.cpp
+++ b/src/planner/operator/logical_insert.cpp
@@ -14,7 +14,7 @@ LogicalInsert::LogicalInsert(TableCatalogEntry &table, idx_t table_index)
 LogicalInsert::LogicalInsert(ClientContext &context, const unique_ptr<CreateInfo> table_info)
     : LogicalOperator(LogicalOperatorType::LOGICAL_INSERT),
       table(Catalog::GetEntry<TableCatalogEntry>(context, table_info->catalog, table_info->schema,
-                                                 dynamic_cast<CreateTableInfo &>(*table_info).table)) {
+                                                 checked_dynamic_cast<CreateTableInfo &>(*table_info).table)) {
 }
 
 idx_t LogicalInsert::EstimateCardinality(ClientContext &context) {
diff --git a/src/planner/operator/logical_update.cpp b/src/planner/operator/logical_update.cpp
index e66dd36d1a..7fe2e907e1 100644
--- a/src/planner/operator/logical_update.cpp
+++ b/src/planner/operator/logical_update.cpp
@@ -12,7 +12,7 @@ LogicalUpdate::LogicalUpdate(TableCatalogEntry &table)
 LogicalUpdate::LogicalUpdate(ClientContext &context, const unique_ptr<CreateInfo> &table_info)
     : LogicalOperator(LogicalOperatorType::LOGICAL_UPDATE),
       table(Catalog::GetEntry<TableCatalogEntry>(context, table_info->catalog, table_info->schema,
-                                                 dynamic_cast<CreateTableInfo &>(*table_info).table)) {
+                                                 checked_dynamic_cast<CreateTableInfo &>(*table_info).table)) {
 }
 
 idx_t LogicalUpdate::EstimateCardinality(ClientContext &context) {
diff --git a/src/storage/checkpoint_manager.cpp b/src/storage/checkpoint_manager.cpp
index 1f97b538ff..5e16d11840 100644
--- a/src/storage/checkpoint_manager.cpp
+++ b/src/storage/checkpoint_manager.cpp
@@ -576,8 +576,8 @@ void CheckpointReader::ReadTableData(ClientContext &context, Deserializer &deser
 	}
 
 	// FIXME: icky downcast to get the underlying MetadataReader
-	auto &binary_deserializer = dynamic_cast<BinaryDeserializer &>(deserializer);
-	auto &reader = dynamic_cast<MetadataReader &>(binary_deserializer.GetStream());
+	auto &binary_deserializer = checked_dynamic_cast<BinaryDeserializer &>(deserializer);
+	auto &reader = checked_dynamic_cast<MetadataReader &>(binary_deserializer.GetStream());
 
 	MetadataReader table_data_reader(reader.GetMetadataManager(), table_pointer);
 	TableDataReader data_reader(table_data_reader, bound_info);
